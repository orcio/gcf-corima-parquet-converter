name: Test Cloud Function Conversion

on:
  workflow_dispatch:
  push:
    branches: [ main ]

jobs:
  test-conversion:
    runs-on: ubuntu-latest
    env:                           # <-- secrets OK qui
      BUCKET_NAME: ${{ secrets.GCS_BUCKET }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true

      - name: Verify bucket exists
        run: gsutil ls -b gs://${BUCKET_NAME}

      # timestamp univoco per cartella test
      - name: Upload test files
        id: upload
        run: |
          TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)
          TEST_PREFIX="dati_raw/test_${TIMESTAMP}"

          # cartella sorgente già presente (senza duplicare il nome bucket!)
          SAMPLE_PREFIX="dati_raw/corima-data/LAF1_20250711_16_22_17"

          gsutil -m cp "gs://${BUCKET_NAME}/${SAMPLE_PREFIX}/*.dat" \
                        "gs://${BUCKET_NAME}/${TEST_PREFIX}/"
          gsutil -m cp "gs://${BUCKET_NAME}/${SAMPLE_PREFIX}/*.json" \
                        "gs://${BUCKET_NAME}/${TEST_PREFIX}/"

          echo "TEST_PREFIX=${TEST_PREFIX}" >> $GITHUB_ENV

      - name: Wait for output Parquet
        run: |
          SAMPLE_FOLDER=${SAMPLE_PREFIX##*/}      # LAF1_20250711_16_22_17
          alias=${SAMPLE_FOLDER%%_*}              # LAF1
          yyyymmdd=${SAMPLE_FOLDER#*_}
          yyyymmdd=${yyyymmdd%%_*}                # 20250711
          dt="${yyyymmdd:0:4}/${yyyymmdd:4:2}/${yyyymmdd:6:2}"
          DEST_PATH="${alias}/${dt}/iis3dwb_acc.parquet"
          echo "DEST_PATH=${DEST_PATH}" >> $GITHUB_ENV

          for i in {1..30}; do
            if gsutil -q stat "gs://${BUCKET_NAME}/${DEST_PATH}"; then
              echo "Found gs://${BUCKET_NAME}/${DEST_PATH}"
              exit 0
            fi
            sleep 10
          done
          echo "Parquet not found"
          exit 1

      - name: Validate Parquet
        run: |
          gsutil cp "gs://${BUCKET_NAME}/${DEST_PATH}" output.parquet
          python - <<EOF
            import pandas as pd, sys, os
            df = pd.read_parquet("output.parquet")
            assert "alias" in df.columns, "missing alias"
            assert df["Time"].dtype == "int64", "Time not int64"
            print("✅ parquet ok, rows:", len(df))
            EOF
